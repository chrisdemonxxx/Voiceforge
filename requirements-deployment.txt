# VoiceForge API - Python ML Dependencies for 80GB A100 GPU Deployment
# Production-ready ML stack with REAL models configured

# ============================================================================
# Core ML Framework (CUDA 12.1 wheels for GPU support)
# ============================================================================
# NOTE: PyTorch with CUDA 12.1 is installed separately in Dockerfile
# to ensure proper CUDA wheel installation. Do not add torch/torchaudio here.
transformers==4.46.1
accelerate==0.27.2
optimum==1.18.0
einops==0.7.0

# ============================================================================
# Text-to-Speech (TTS) Models - PRODUCTION READY
# ============================================================================
# Chatterbox TTS - ResembleAI (MIT License, 500M params, multilingual)
chatterbox-tts==0.1.0

# Higgs Audio V2 - Boson AI (3B params, 24kHz, expressive TTS)
# Install from source as no official pip package exists
# git+https://github.com/boson-ai/higgs-audio.git

# StyleTTS2 - Human-level TTS (pip installable wrapper)
styletts2==0.1.7

# Fallback TTS for compatibility
TTS==0.22.0

# ============================================================================
# Speech-to-Text (STT) - PRODUCTION READY
# ============================================================================
# faster-whisper with large-v3 model (OpenAI Whisper optimized with CTranslate2)
faster-whisper==1.2.1
ctranslate2==4.4.0
openai-whisper==20231117

# ============================================================================
# Voice Activity Detection (VAD) - PRODUCTION READY
# ============================================================================
# Silero VAD v5.1 (MIT License, torch hub + pip package)
silero-vad==6.2.0
silero==0.4.2
webrtcvad==2.0.10

# ============================================================================
# Voice Large Language Model (VLLM) - PRODUCTION READY
# ============================================================================
# vLLM for Llama-3.3-70B-Instruct (70B params, ~60-75GB VRAM)
# NOTE: Using latest vLLM 0.6+ for better Llama 3.3 support
vllm==0.6.0
sentencepiece==0.2.0
protobuf==4.25.3
xformers==0.0.27

# ============================================================================
# Voice Cloning
# ============================================================================
resemblyzer==0.1.1.dev0
speechbrain==0.5.16

# ============================================================================
# Audio Processing
# ============================================================================
# NOTE: numpy and numba are pre-installed in requirements-build.txt
librosa==0.10.1
soundfile==0.12.1
pydub==0.25.1
audioread==3.0.1
resampy==0.4.2
scipy==1.11.4

# ============================================================================
# Model Management & Optimization
# ============================================================================
# NOTE: bitsandbytes version must match torch CUDA wheel (cu121)
# NOTE: huggingface-hub >=0.23.2 required by transformers 4.46.1
huggingface-hub==0.23.2
safetensors==0.4.1
bitsandbytes==0.42.0
flashattention==2.5.0
peft==0.12.0

# ============================================================================
# API & Web Framework
# ============================================================================
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-multipart==0.0.6
aiofiles==23.2.1
gradio==4.19.1

# ============================================================================
# Utilities
# ============================================================================
pyyaml==6.0.1
python-dotenv==1.0.0
requests==2.31.0
httpx==0.26.0
pillow==10.2.0
tqdm==4.66.1
loguru==0.7.2
psutil==5.9.7

# ============================================================================
# Testing & Development
# ============================================================================
pytest==7.4.4
pytest-asyncio==0.23.3
